---
layout: post
title: 'Image Obfuscation'
author: Jinwoo Nam
date: 2019-05-15 22:00
tags: [Image Security]
image: /files/covers/obfus.jpg
---

# Project Description

### Image Obfuscation

> [디테일한 내용을 생략하고 후기로 넘어가려면 여기를 클릭](#후기)

> [자세한 내용은 Deeping Source Inc.의 공식 문서를 참조](https://www.deepingsource.io/privacy-protection?lang=ko)

Image obfuscation은 이미지 데이터셋을 처리하여 이미지가 다음의 두 가지 성질을 만족하도록 하는 것입니다.
* 익명성: 이미지 내부의 개인정보(얼굴 등)은 사람이 알아볼 수 없는 형태로 가공되어야 하며, 제 3자가 원본을 복원할 수도 없어야 합니다.
* 데이터 활용도: 익명화된 이미지로 기계학습 모델을 학습시키더라도 원본 이미지로 학습한 것과 비슷한 성능을 내어야 합니다.

이전까지 대부분의 Image Obfuscation은 개인정보를 탐지한 뒤(Detection) 이를 지워버리는 방식으로 동작했습니다. 그러나 이러한 방법은 데이터의 활용도를 떨어뜨릴 뿐더러, 탐지 과정에서 개인정보를 놓칠 경우 익명성이 보장되지 않을 수도 있다는 치명적인 문제가 있습니다.


# Approach

>많은 디테일이 생략되었으며 웹 상에 공개된 내용만을 적은 점 양해 부탁드립니다.

새로운 방식의 Image Obfuscation은 다음의 아이디어에서 출발하였습니다.
* 개인정보를 자동적으로 모두 찾는 것은 어렵다. 그냥 이미지 전체를 비식별화 하는 것이 좋다
* 단순한 방식으로 Image Obfuscation을 하면 원본 이미지가 복원당할 위험성이 있으며, Obfuscated Image의 데이터 활용도를 보존할 수 없다. 따라서 인공신경망을 활용하는 것이 바람직하다
    * Multi-Task Learning을 통해 익명성과 활용도를 모두 학습할 수 있다
    * 인공신경망 아웃풋에서 원본을 복원하는 것은 매우 힘들다. 따라서 원본 이미지가 복원당할 위험성이 매우 적다.

### Training

![Obfuscation Training Procedure](/files/images/obfus/training.jpg)

Obfuscation 모델을 학습하기 위해 Adversarial Training 및 Multi-task learning기법을 사용하였습니다. 먼저 이미지를 익명화하기 위해 Reference Obfuscation(Noise, Jittering 등의 합성)된 이미지를 만들고, 이것을 타겟으로 하여 익명성을 검사하는 Adversarial Training을 합니다. 이 중간에 나오는 Obfuscated Image로 Target Task를 학습하여 데이터의 활용성을 보장하고 이후 Inference 과정에 사용될 신경망을 학습합니다.

이 과정에서 Obfuscator 모델은 인풋 이미지에서 Target Task에 필요한 정보는 남기고 필요없는 정보는 지워서 이미지를 사람이 인식하지 못하는 형태로 바꾸는 법을 학습합니다.


### Inference

![Obfuscation Inference Procedure](/files/images/obfus/inference.jpg)

Inference 시에는 앞의 단계에서 활용된 Obfuscator 모델(_O_)와 Target Task 모델(_F_)를 모두 활용합니다. Inference 과정에서 인풋이 들어오면 Trained Obfuscator를 이용하여 이를 먼저 프로세싱한 뒤, 여기서 나온 아웃풋을 Target Task 모델에 인풋으로 넣어 Target Task를 수행합니다.

### How it Works?
![Obfuscation Mapping](/files/images/obfus/scheme.jpg)
위 그림은 개발된 Obfuscator 모델이 어떻게 동작하는 지 설명하는 그림입니다. 그림에서 _O_는 Obfuscator 매핑, F는 원본 이미지에 학습된 Target Task 모델의 Decision Boundary, F0는 Obfuscated Image에 학습된 Target Task 모델의 Decision Boundary입니다.

그림에서 Obfuscator(_O_)는 회색 영역의 원본 이미지를 노란색 영역으로 매핑하는 역할을 합니다. 그런데 이 Obfuscator는 Target Task의 Decision Boundary를 최대한 유지하도록 학습되었기 때문에 이미지의 형태는 다르게 하면서도(_O_ 매핑) 원본 이미지에 대한 Target Task 모델의 Decision Boundary는 비슷하게 (회색 영역에서 F와 F0 비교) 유지할 수 있습니다.

### Obfuscation for Bigger Image

![Obfuscation for big image fails](/files/images/obfus/big-fail.jpg)

앒에 설명한 것과 같은 Image Obfuscation은 데이터의 익명성과 활용성이라는 두 가지 목표를 모두 만족시킬 수 있으나, 커다란 이미지에서는 Obfuscator의 학습이 Target Task loss에 좌우되어 Obfuscator가 계속 원본 이미지과 같은 이미지를 만드는 현상이 발생합니다(위의 그림, (a)). 이는 커다란 이미지에서는 가능한 이미지의 경우의 수가 크게 늘어 Adversarial Learning Objective가 크게 어려워지기 때문입니다.

![obfuscation for big image](/files/images/obfus/bigobfus.jpg)

커다란 이미지에서 Obfuscation이 제대로 되지 않는 현상을 완화하기 위해, 여기서는 Pretrained Autoencoder를 사용햐여 Adversarial Learning의 난이도를 낮추도록 하였습니다. 위의 그림과 같이, 여기서는 먼저 (a) 이미지의 크기를 줄이기 위한 autoencoder를 학습시킨 뒤 (b) 앞에서 설명한 obfuscator 학습 과정을 이용하였습니다. 이러한 과정을 통해, 커다란 이미지도 obfuscator 입장에서는 작은 이미지와 똑같이 다룰 수 있게 됩니다.

큰 이미지에서 Inference시에는 학습된 Autoencoder와 obfuscator, target task model을 순차적으로 적용합니다. 


# Results
>많은 디테일이 생략되었으며 웹 상에 공개된 내용만을 적은 점 양해 부탁드립니다.

### Quantitative Results
제안된 방식의 효율성을 알아보기 위해 Image Classification, Object Detection, Facial Landmar Detection, Face Varification 등의 다양한 문제에 실험을 진행하였습니다.
모든 문제에서 Original Image로 학습한 모델에 비해 0%-1% 이내의 작은 성능 차이만을 보였습니다.

### Qualitative Results
![Obfuscation Results](/files/images/obfus/celeba-results.jpg)
위의 그림은 제안된 Obfuscation 모델의 결과를 보여줍니다. 위에서부터 차례대로 원본 이미지, Reference Obfuscation, 우리 모델의 Obfuscated Image입니다.
우리 모델의 아웃풋은 원본 이미지와 크게 다르며, 변형 강도는 Reference Obfuscation과도 견줄 수 있습니다.

### Reversibility
![Obfuscation Results](/files/images/obfus/celeba-reverse.jpg)
제안된 모델이 Task와 관련없는 정보를 효과적으로 없앤다는 것을 보이기 위해, Obfuscator를 학습할 때 사용된 원본 데이터가 유출된 상황을 가정한 뒤 Obfuscated Image를 Original Image로 매핑하는 신경망 모델을 학습해 보았습니다. 

그 결과는 위의 그림과 같습니다. 그림은 CelebA Dataset의 Facial Landmark Detection Task에 학습된 Obfuscator 모델을 보여줍니다. 위에서부터 차례대로 원본 이미지, Obfuscated Image, 그리고 복원된 이미지입니다. 설령 원본 트레이닝 데이터가 유출되었다 하더라도, Obfuscator의 역방향 매핑을 학습한 모델은 Obfuscated Image를 잘 복원하지 못하는 모습을 볼 수 있습니다.


# 후기

* 프로젝트가 한창 진행되던 와중에 중간에 끼어들어 협업에 문제가 있었다
    * 처음 해보는 팀 작업이었기에 프로젝트 코드의 디자인 패턴을 배우는 데 시간이 걸렸다. 처음 몇 번은 유지 보수가 힘든 코드를 짰으나, 곧 익숙해졌다. 

* 처음 하는 협업이었기에 커뮤니케이션이 중요했다
    * 처음에는 협업 과정에서 아이디어를 전달하는 데 어려움이 있었다. 그러나 차차 당연하지만 중요한 사실들(말보다 그림이 효과적이다, 내가 당연하게 아는 것을 꼭 상대방이 알고 있지는 않다 ...)을 잊고 있었음을 새삼 깨닫게 되어 원만한 아이디어 교환이 가능해졌다.
    * 내가 참여하기 전까지 obfuscation은 1인 프로젝트였고, 항상 인력이 부족하던 상태였기에 새로이 할 실험이 정말 많았다. 이 때문에 처음 프로젝트에 참여하고 며칠 정도는 아예 실험을 전부 멈추고 실험에 대한 검토를 했다.
