---
layout: post
title: 'Natural Language Video Localization'
author: Jinwoo Nam
date: 2020-09-09 22:00
tags: [Vision and Language]
image: /files/covers/nlvl.jpg
---

# Project Description

> [디테일한 내용을 생략하고 후기로 넘어가려면 여기를 클릭](#후기)

![Natural Language Video Localization](/files/images/nlvl/nlvl.gif)

NC소프트로부터 좋은 기회를 얻어 진행하게 된 프로젝트입니다. Natural Language Video Localization (NLVL)은 위의 영상과 같이 비디오와 자연어 쿼리가 주어졌을 때 비디오에서 쿼리가 가리키는 부분을 찾아내는 문제입니다.


# 내용

> 이제껏 어디에도 공개된 적 없는 내용입니다. 자세한 내용은 공개할 수 없는 점 양해 부탁드립니다.

NLVL을 위해 개발된 DiDeMo[1] 데이터셋에서 (1)당시 가장 높은 성능을 보였던 ASST[2]를 재구현(Reproduce)하고 (2)이를 개량하여 성능을 높이는 것을 주요 목표로 설정하였습니다.

위의 목표를 달성하기 위해 다음과 같은 개선사항을 적용하였습니다.
* 프레임마다 image captioning 한 것을 video feature로 추가하였습니다. 이 형태의 비디오 특징값은 비디오 내부의 object나 action을 단어의 형태로 explicit하게 제시해 줄 수 있어 자연어 쿼리와 연관짓기가 쉽습니다.
* Image captioning은 salient object만을 잡아서 제시하기 때문에, salient하지 않은 object도 제시해 줄 수 있는 frame-wise object detection을 video feature로 추가했습니다.
* 기존의 모델은 여러 종류의 video feature(stream)을 하나의 feature로 묶어 사용하였습니다. 이러한 방식의 feature processing은 각각의 feature stream을 충분히 exploit하지 못한다고 생각하여 각각의 video feature마다 작은 모델을 학습하고 이를 ensemble하는 방법을 사용하였습니다.

# 후기
* 기계학습에서 유명한 격언으로 "악마는 디테일에 있다"라는 말이 있습니다. 이 말대로라면 비디오와 자연어의 조합은 분명 악마 중에서도 가장 사악한 종류일 것입니다.
* 데이터를 처리하기 위해 알아야 할 디테일(노하우)은 많았지만 관련된 정보를 얻을 방법은 극히 제한적이었습니다. 이 때 *타 연구자를 만나고 그들에게서 관련 노하우를 얻은 것*이 도움이 많이 되었습니다.
    * 프로젝트를 시작할 당시 연구실 내에 자연어나 비디오를 처리해 본 사람이 없었기 때문에 모든 것을 제가 직접 부딛혀 보고 알아내야 할 처지였습니다. 
    * 그러나, 혼자 모든 것을 시도해 보는 것은 현실적으로 어려웠기 때문에 *타 연구자를 만나고 그들에게서 관련 노하우를 얻어보려는*노력을 많이 했습니다. 몇몇 유명 학회(ICCV,KCCV)에 직접 참여하여 국내 유수 연구진들을 만나 비디오 처리에 관한 조언을 들었고, 우연한 기회로 버클리에서 근무하시는 한국인 연구자 분을 만나 자연어 처리에 관한 노하우를 얻었습니다.




---
[1] Hendricks et al. "Localizing Moments in Video with Temporal Language", ICCV, 2017
[2] Yang et al. "Attentive Sequence to Sequence Translation for Localizing Clips of Interest by Natural Language Descriptions", Arxiv preprint, 2018